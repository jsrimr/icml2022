\section{Proposed Method}
The main idea of our approach is to combine the learned skills to utilize for downstream tasks. We follow DIAYN \cite{eysenbach2018diversity} framework since it is used as a general skill discovery baseline, but our work is not limited to..

\subsection{Skill-agnostic Policy}


We assume that the skill discovery step is done so that we now have a pretrained skill-conditioned policy $\pi(a|s,z)$ which outputs action given the state and skill. Also, the skill $z$ is a $k$-dimensional discrete random variable sampled from the distribution $p(z)$. Then we can write a skill-agnostic policy as
\begin{equation}
    \pi(a|s) = \mathbb{E}_{z \sim p(z|s)}[\pi(a|s,z)].
\end{equation}
One can fine-tune either a \emph{controller} $p(z|s)$ with or without further fine-tuning a skill-conditioned policy $\pi(a|s,z)$ in hierarchical RL framework \cite{sharma2019dynamics}. If we assume that skill distribution is independent to the state $p(z) \approx p(z|s)$, it becomes a simple fine-tuning formulation either fixing one skill to adapt a task or take action proportional to the dominant skill. The limitation of those methods is to combine the skills only in an action level rather than underlying representation level.

\subsection{Mixed Representations}
We decompose a skill-conditioned policy to $\pi(a|s,z) = f_{\psi}(g_{\phi}(s, z))$ where $f_{\psi}$ is a linear classifier and $g_{\phi}$ is the rest. Then, we write a skill-agnostic policy as
\begin{equation}
    \tilde{\pi}(a|s) = f_{\psi}(\mathbb{E}_{z \sim p(z|s)}[g_{\phi}(s,z)])
\end{equation}

We consider $g_{\phi}(s, z)$ to be a state representation from the view of skill $z$. In other words, as many representations as the number of skills are created for one state. In this formulation, state representations are \emph{mixed} over the skills by the controller $p(z|s)$. As above, we may replace $p(z|s)$ to $p(z)$ for simplifying. In this case, we only need an additional weights on the simplex $w \in \Delta^k$ for $f_{\psi}(\mathbb{E}_{z \sim p(z)}[g_{\phi}(s,z)]) = f_{\psi}(\sum_i w_i g_{\phi}(s,z_i))$. 

TODO: Figure for method

\subsection{Analyzation}
TODO: analyze a trajectory and the representations of each state


